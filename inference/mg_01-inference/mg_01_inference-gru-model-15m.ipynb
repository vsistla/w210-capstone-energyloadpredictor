{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    " # MG_01 Inference - Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import mysql.connector\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "from calendar import month_abbr\n",
    "from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error, mean_squared_error, mean_squared_log_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import datetime\n",
    "import tempfile\n",
    "import boto3\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from matplotlib import rc\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Start Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_access_key_id = 'AKIATAVK2UELBEVSLANM'\n",
    "aws_secret_access_key = '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'\n",
    "\n",
    "s3_client = boto3.client('s3', \n",
    "                         aws_access_key_id=aws_access_key_id, \n",
    "                         aws_secret_access_key=aws_secret_access_key)\n",
    "\n",
    "bucket_name = 'ipowermigrid.15m.models'\n",
    "# read from S3 bucket\n",
    "key = 'gru_X_standardscalar-15m.pkl'\n",
    "with tempfile.TemporaryFile() as fp:\n",
    "    s3_client.download_fileobj(Fileobj=fp, Bucket=bucket_name, Key=key)\n",
    "    fp.seek(0)\n",
    "    gru_X_scaler = joblib.load(fp)\n",
    "    \n",
    "key = 'gru_y_standardscalar-15m.pkl'\n",
    "with tempfile.TemporaryFile() as fp:\n",
    "    s3_client.download_fileobj(Fileobj=fp, Bucket=bucket_name, Key=key)\n",
    "    fp.seek(0)\n",
    "    gru_y_scaler = joblib.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.GRU(200, activation='relu', return_sequences=True, input_shape=(960,6)))\n",
    "model.add(tf.keras.layers.GRU(100, activation='relu') )\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "model.load_weights('grumodel_15m_best_final.hdf5') \n",
    "model.compile(loss='mae', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_14 (GRU)                (None, 960, 200)          124800    \n",
      "                                                                 \n",
      " gru_15 (GRU)                (None, 100)               90600     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 215,501\n",
      "Trainable params: 215,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to sql database\n",
    "credentials = 'mysql://capstone_user:Capstone22!@capstone-database.czwmid1hzf1x.us-west-2.rds.amazonaws.com/mysqldb'\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"capstone-database.czwmid1hzf1x.us-west-2.rds.amazonaws.com\",\n",
    "  user=\"capstone_user\",\n",
    "  password=\"Capstone22!\",\n",
    "  database=\"mysqldb\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "# set params\n",
    "####################################\n",
    "mg_id = 'mg_01'\n",
    "\n",
    "params = {\n",
    "    'mg_id':mg_id\n",
    "}\n",
    "####################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2021-03-27 09:15:00')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tail = pd.read_sql('''SELECT * FROM microgrid_actuals_15m WHERE id = %(mg_id)s ORDER BY end DESC LIMIT 960''', \n",
    "                                  con=credentials, params=params)\n",
    "\n",
    "tail['day_of_week'] = tail['end'].dt.day_name()\n",
    "\n",
    "tail['day_of_week_int'] = tail['end'].dt.day_of_week\n",
    "\n",
    "date_range = pd.date_range(start='2019-01-01', end='2022-01-27')\n",
    "\n",
    "cal = calendar()\n",
    "holidays = cal.holidays(start=date_range.min(), end=date_range.max())\n",
    "\n",
    "tail['holiday'] = tail['end'].dt.date.astype('datetime64').isin(holidays)\n",
    "\n",
    "tail[\"holiday_int\"] = tail[\"holiday\"].astype(int)\n",
    "\n",
    "time = tail['end'].iloc[-1]\n",
    "\n",
    "tail = tail[['demand', 'temp', 'humidity', 'month_int', 'day_of_week_int', 'holiday_int']].copy() \n",
    "tail\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data here\n",
    "# MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = tail.to_numpy()\n",
    "X_pred = X_pred.reshape(1, 5760)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1216.,   57.,   78., ...,    3.,    5.,    0.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_pred = X_pred.reshape((1, 960, 6))\n",
    "# X_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use X_scalar to transform x\n",
    "X_pred = gru_X_scaler.transform(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 960, 6)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pred = X_pred.reshape((1, 960, 6))\n",
    "X_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.predict(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1182.9308]], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inverse tranfrom y from y_scalar\n",
    "y = gru_y_scaler.inverse_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_access_key_id = 'AKIATAVK2UELBEVSLANM'\n",
    "aws_secret_access_key = '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'\n",
    "\n",
    "s3_client = boto3.client('s3', \n",
    "                         aws_access_key_id=aws_access_key_id, \n",
    "                         aws_secret_access_key=aws_secret_access_key)\n",
    "bucket_name = 'ipowermigrid.15m.models'\n",
    "key = 'grumodel_15m_best.hdf5'\n",
    "\n",
    "# read from \n",
    "# with tempfile.TemporaryFile() as fp:\n",
    "#     s3_client.download_fileobj(Fileobj=fp, Bucket=bucket_name, Key=key)\n",
    "#     fp.seek(0)\n",
    "#     gru_model = joblib.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"\"\"\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"\"\"\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"\"\"\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"\"\"\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"\"\"\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"\"\"\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"\"\"\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"\"\"\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"\"\"\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"\"\"\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"\"\"\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"\"\"\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"\"\"\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"\"\"\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"\"\"\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"\"\"\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"\"\"\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"\"\"\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"\"\"\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "def lagged_data_pred(df):\n",
    "    df = df#[['end','id', 'demand', 'temp', 'humidity']]\n",
    "    for i in range(1, 672):\n",
    "        df[\"demand_lag_{}\".format(i)] = df['demand'].shift(i)\n",
    "        df[\"temp_lag_{}\".format(i)] = df['temp'].shift(i)\n",
    "        df[\"humidity_lag_{}\".format(i)] = df['humidity'].shift(i)\n",
    "\n",
    "    df = pd.DataFrame(df.iloc[-1]).T\n",
    "    return df\n",
    "\n",
    "def ModelPredictions(model, X_pred, mg_id):\n",
    "    prediction = model.predict(X_pred.drop(['end'], axis=1))\n",
    "    results = pd.DataFrame({'end':X_pred.end,\n",
    "                        'id':mg_id,\n",
    "                        'demand':prediction.round(1)  \n",
    "                       })    \n",
    "    return results\n",
    "\n",
    "\n",
    "# connect to sql database\n",
    "credentials = 'mysql://capstone_user:Capstone22!@capstone-database.czwmid1hzf1x.us-west-2.rds.amazonaws.com/mysqldb'\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"capstone-database.czwmid1hzf1x.us-west-2.rds.amazonaws.com\",\n",
    "  user=\"capstone_user\",\n",
    "  password=\"Capstone22!\",\n",
    "  database=\"mysqldb\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "# set params\n",
    "####################################\n",
    "mg_id = 'mg_01'\n",
    "\n",
    "params = {\n",
    "    'mg_id':mg_id\n",
    "}\n",
    "####################################\n",
    "\n",
    "def inference(mg_id, params=params):\n",
    "    tail = pd.read_sql('''SELECT * FROM microgrid_actuals_15m WHERE id = %(mg_id)s ORDER BY end DESC LIMIT 960''', \n",
    "                                  con=credentials, params=params)\n",
    "    # invert the data frame\n",
    "    tail = tail.iloc[::-1]\n",
    "    # select the lastest date in the actuals table\n",
    "    date = tail.iloc[-1]['end']\n",
    "    # return a fixed frequency DatetimeIndex; grab the lastest date \n",
    "    time_index = pd.date_range(date, periods=16, freq='min')[-1]\n",
    "    # fill in empty record with latest date\n",
    "    tail.loc[tail.shape[0]] = [time_index, mg_id, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "\n",
    "    tail['month'] = tail['end'].dt.strftime('%b')\n",
    "\n",
    "    lower_ma = [m.lower() for m in month_abbr]\n",
    "\n",
    "    # one-liner with Pandas\n",
    "    tail['month_int'] = tail['month'].str.lower().map(lambda m: lower_ma.index(m)).astype('Int8')\n",
    "\n",
    "    tail['day_of_week'] = tail['end'].dt.day_name()\n",
    "\n",
    "    tail['day_of_week_int'] = tail['end'].dt.day_of_week\n",
    "\n",
    "    date_range = pd.date_range(start='2019-01-01', end='2022-01-27')\n",
    "\n",
    "    cal = calendar()\n",
    "    holidays = cal.holidays(start=date_range.min(), end=date_range.max())\n",
    "\n",
    "    tail['holiday'] = tail['end'].dt.date.astype('datetime64').isin(holidays)\n",
    "\n",
    "    tail[\"holiday_int\"] = tail[\"holiday\"].astype(int)\n",
    "\n",
    "    tail = tail[['end', 'id','demand', 'temp', 'humidity', 'month_int', 'day_of_week_int', 'holiday_int']].copy() \n",
    "\n",
    "    # transform records to lagged data format\n",
    "    pred = lagged_data_pred(tail)\n",
    "\n",
    "    X_pred = pred.drop(['id','demand', 'temp', 'humidity'], axis=1)\n",
    "\n",
    "    # set predict value\n",
    "    results = ModelPredictions(lr_from_s3, X_pred, mg_id)\n",
    "    # write results to sql table\n",
    "    results.to_sql('microgrid_predictions_15m', con=credentials, if_exists='append', index=False)\n",
    "\n",
    "    # select the next time step to predict\n",
    "    actual  = pd.read_sql('''SELECT * FROM microgrid_test_15m WHERE id = %(mg_id)s ORDER BY end LIMIT 1''', \n",
    "                          con=credentials, params=params)\n",
    "    # write next actual from the test table to the actual table\n",
    "    actual.to_sql('microgrid_actuals_15m', con=credentials, if_exists='append', index=False)\n",
    "    # delete updated record from test table\n",
    "    sql = \"DELETE FROM microgrid_test_15m WHERE id = '%s' AND end = '%s'\" % (mg_id, str(actual.iloc[0][0]))\n",
    "    mycursor.execute(sql)\n",
    "    mydb.commit()\n",
    "        \n",
    "inference(mg_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
