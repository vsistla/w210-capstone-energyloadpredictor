{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # MG_01 Inference - Ensemble Model - 24 Hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import mysql.connector\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "from calendar import month_abbr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error, mean_squared_error, mean_squared_log_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import datetime\n",
    "import tempfile\n",
    "import boto3\n",
    "import joblib\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_access_key_id = 'AKIATAVK2UELBEVSLANM'\n",
    "aws_secret_access_key = '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'\n",
    "\n",
    "s3_client = boto3.client('s3', \n",
    "                         aws_access_key_id=aws_access_key_id, \n",
    "                         aws_secret_access_key=aws_secret_access_key)\n",
    "\n",
    "bucket_name = 'ipowermigrid.24h.models'\n",
    "key = 'linear_model_24h.joblib'\n",
    "# read model from S3 bucket\n",
    "with tempfile.TemporaryFile() as fp:\n",
    "    s3_client.download_fileobj(Fileobj=fp, Bucket=bucket_name, Key=key)\n",
    "    fp.seek(0)\n",
    "    lr_model = joblib.load(fp)\n",
    "\n",
    "key = 'randomforest_model_24h.joblib'\n",
    "with tempfile.TemporaryFile() as fp:\n",
    "    s3_client.download_fileobj(Fileobj=fp, Bucket=bucket_name, Key=key)\n",
    "    fp.seek(0)\n",
    "    rf_model = joblib.load(fp)\n",
    "    \n",
    "key = 'randomforest_model_24h.joblib'\n",
    "with tempfile.TemporaryFile() as fp:\n",
    "    s3_client.download_fileobj(Fileobj=fp, Bucket=bucket_name, Key=key)\n",
    "    fp.seek(0)\n",
    "    xgb_model = joblib.load(fp)\n",
    "\n",
    "key = 'knnr_model_24h.joblib'\n",
    "with tempfile.TemporaryFile() as fp:\n",
    "    s3_client.download_fileobj(Fileobj=fp, Bucket=bucket_name, Key=key)\n",
    "    fp.seek(0)\n",
    "    knn_model = joblib.load(fp)\n",
    "    \n",
    "key = 'svr_model_24h.joblib'\n",
    "with tempfile.TemporaryFile() as fp:\n",
    "    s3_client.download_fileobj(Fileobj=fp, Bucket=bucket_name, Key=key)\n",
    "    fp.seek(0)\n",
    "    svr_model = joblib.load(fp)\n",
    "    \n",
    "key = 'ensemble_model_24h.joblib'\n",
    "with tempfile.TemporaryFile() as fp:\n",
    "    s3_client.download_fileobj(Fileobj=fp, Bucket=bucket_name, Key=key)\n",
    "    fp.seek(0)\n",
    "    ensemble_model = joblib.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to sql database\n",
    "credentials = 'mysql://capstone_user:Capstone22!@capstone-database.czwmid1hzf1x.us-west-2.rds.amazonaws.com/mysqldb'\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"capstone-database.czwmid1hzf1x.us-west-2.rds.amazonaws.com\",\n",
    "  user=\"capstone_user\",\n",
    "  password=\"Capstone22!\",\n",
    "  database=\"mysqldb\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "# set params\n",
    "####################################\n",
    "mg_id = 'mg_01'\n",
    "\n",
    "params = {\n",
    "    'mg_id':mg_id\n",
    "}\n",
    "####################################\n",
    "actuals = pd.read_sql('''SELECT * FROM microgrid_actuals_hr_24 WHERE id = %(mg_id)s''', \n",
    "                                      con=credentials, params=params)\n",
    "\n",
    "# set prediction month\n",
    "actuals['month'] = actuals['end'].dt.strftime('%b')\n",
    "lower_ma = [m.lower() for m in month_abbr]\n",
    "actuals['month_int'] = actuals['month'].str.lower().map(lambda m: lower_ma.index(m)).astype('Int8')\n",
    "actuals['day_of_week'] = actuals['end'].dt.day_name()\n",
    "actuals['day_of_week_int'] = actuals['end'].dt.day_of_week\n",
    "date_range = pd.date_range(start='2019-01-01', end='2022-01-27')\n",
    "cal = calendar()\n",
    "holidays = cal.holidays(start=date_range.min(), end=date_range.max())\n",
    "actuals['holiday'] = actuals['end'].dt.date.astype('datetime64').isin(holidays)\n",
    "actuals[\"holiday_int\"] = actuals[\"holiday\"].astype(int)\n",
    "actuals = actuals[['end', 'id',  'month_int', 'day_of_week_int', 'holiday_int', 'demand', 'temp', 'humidity']].copy()\n",
    "\n",
    "for i in range(1, 10):\n",
    "    actuals[\"demand_lag_{}\".format(i)] = actuals['demand'].shift(i)\n",
    "    actuals[\"temp_lag_{}\".format(i)] = actuals['temp'].shift(i)\n",
    "    actuals[\"humidity_lag_{}\".format(i)] = actuals['humidity'].shift(i)\n",
    "    \n",
    "y_actuals = actuals.dropna()['demand']\n",
    "y_actuals = y_actuals.values.reshape((len(y),1))\n",
    "\n",
    "\n",
    "X_actuals = actuals.dropna().drop(['end', 'id','demand', 'temp', 'humidity'], axis=1)\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "X_actuals_scaled = sc_X.fit_transform(X_actuals)\n",
    "y_actuals_scaled = sc_y.fit_transform(y_actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagged_data_pred(df, lags):\n",
    "    df = df#[['end','id', 'demand', 'temp', 'humidity']]\n",
    "    for i in range(1, lags):\n",
    "        df[\"demand_lag_{}\".format(i)] = df['demand'].shift(i)\n",
    "        df[\"temp_lag_{}\".format(i)] = df['temp'].shift(i)\n",
    "        df[\"humidity_lag_{}\".format(i)] = df['humidity'].shift(i)\n",
    "\n",
    "    df = pd.DataFrame(df.iloc[-1]).T\n",
    "    return df\n",
    "\n",
    "def ModelPredictions(model, X_pred, mg_id):\n",
    "    prediction = model.predict(X_pred.drop(['end'], axis=1))\n",
    "    results = pd.DataFrame({'end':X_pred.end,\n",
    "                        'id':mg_id,\n",
    "                        'demand':prediction.round(1)  \n",
    "                       })    \n",
    "    return results\n",
    "\n",
    "# def SVRModelPredictions(model, X_pred, mg_id):\n",
    "#     prediction = model.predict(X_pred)\n",
    "#     print(prediction)\n",
    "#     prediction = prediction.reshape((1,))\n",
    "#     print(prediction)\n",
    "#     results = pd.DataFrame({'id':mg_id,\n",
    "#                         'demand':prediction\n",
    "#                        })   \n",
    "#     print(results['demand'])\n",
    "#     results = sc_y.inverse_transform(results['demand'].to_numpy().reshape((1,1)))\n",
    "    \n",
    "#     return results\n",
    "\n",
    "def SVRModelPredictions(model, X_pred, mg_id, time_index):\n",
    "    prediction = model.predict(X_pred)\n",
    "    prediction = prediction.reshape((1,-1))\n",
    "    prediction = sc_y.inverse_transform(prediction)\n",
    "    results = pd.DataFrame({'end':time_index,\n",
    "                            'id':mg_id,\n",
    "                            'demand':prediction[0].round(1)\n",
    "                           }) \n",
    "    return results\n",
    "\n",
    "tail = pd.read_sql('''SELECT * FROM microgrid_actuals_hr_24 WHERE id = %(mg_id)s ORDER BY end DESC LIMIT 10''', \n",
    "                                      con=credentials, params=params)\n",
    "# invert the data frame\n",
    "tail = tail.iloc[::-1]\n",
    "# select the lastest date in the actuals table\n",
    "date = tail.iloc[-1]['end']\n",
    "# return a fixed frequency DatetimeIndex; grab the lastest date \n",
    "time_index = pd.date_range(date, periods=25, freq='h')[-1]\n",
    "# fill in empty record with latest date\n",
    "tail.loc[tail.shape[0]] = [time_index, mg_id, np.nan, np.nan, np.nan, np.nan]\n",
    "# set prediction month\n",
    "tail['month'] = tail['end'].dt.strftime('%b')\n",
    "lower_ma = [m.lower() for m in month_abbr]\n",
    "tail['month_int'] = tail['month'].str.lower().map(lambda m: lower_ma.index(m)).astype('Int8')\n",
    "tail['day_of_week'] = tail['end'].dt.day_name()\n",
    "tail['day_of_week_int'] = tail['end'].dt.day_of_week\n",
    "date_range = pd.date_range(start='2019-01-01', end='2022-01-27')\n",
    "cal = calendar()\n",
    "holidays = cal.holidays(start=date_range.min(), end=date_range.max())\n",
    "tail['holiday'] = tail['end'].dt.date.astype('datetime64').isin(holidays)\n",
    "tail[\"holiday_int\"] = tail[\"holiday\"].astype(int)\n",
    "tail = tail[['end', 'id',  'month_int', 'day_of_week_int', 'holiday_int', 'demand', 'temp', 'humidity']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_demand</th>\n",
       "      <th>rf_demand</th>\n",
       "      <th>xgb_demand</th>\n",
       "      <th>knn_demand</th>\n",
       "      <th>svr_demand</th>\n",
       "      <th>month_int</th>\n",
       "      <th>day_of_week_int</th>\n",
       "      <th>holiday_int</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-04-01</th>\n",
       "      <td>114460.0</td>\n",
       "      <td>113387.2</td>\n",
       "      <td>113387.2</td>\n",
       "      <td>113536.3</td>\n",
       "      <td>112925.3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lr_demand  rf_demand  xgb_demand  knn_demand  svr_demand  \\\n",
       "end                                                                    \n",
       "2021-04-01   114460.0   113387.2    113387.2    113536.3    112925.3   \n",
       "\n",
       "            month_int  day_of_week_int  holiday_int  \n",
       "end                                                  \n",
       "2021-04-01          4                3            0  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lag data\n",
    "lr_pred = lagged_data_pred(tail, 10)\n",
    "rf_pred = lagged_data_pred(tail, 10)\n",
    "xgb_pred = lagged_data_pred(tail, 10)\n",
    "knn_pred = lagged_data_pred(tail, 10)\n",
    "svr_pred = lagged_data_pred(tail, 10)\n",
    "\n",
    "# # prepare model X pred\n",
    "lr_X_pred = lr_pred.drop(['id','demand', 'temp', 'humidity'], axis=1)\n",
    "rf_X_pred = rf_pred.drop(['id','demand', 'temp', 'humidity'], axis=1)\n",
    "xgb_X_pred = xgb_pred.drop(['id','demand', 'temp', 'humidity'], axis=1)\n",
    "knn_X_pred = knn_pred.drop(['id','demand', 'temp', 'humidity'], axis=1)\n",
    "svr_X_pred = svr_pred.drop(['end','id','demand', 'temp', 'humidity'], axis=1)\n",
    "svr_X_pred_scaled = sc_X.transform(svr_X_pred)\n",
    "\n",
    "# # prediction results\n",
    "# #.rename(columns={\"demand\": \"lr_demand\"})\n",
    "lr_results = ModelPredictions(lr_model, lr_X_pred, mg_id).set_index('end').rename(columns={\"demand\": \"lr_demand\"}) \n",
    "rf_results = ModelPredictions(rf_model, rf_X_pred, mg_id).set_index('end').rename(columns={\"demand\": \"rf_demand\"}) \n",
    "xgb_results = ModelPredictions(rf_model, xgb_X_pred, mg_id).set_index('end').rename(columns={\"demand\": \"xgb_demand\"}) \n",
    "knn_results = ModelPredictions(knn_model, knn_X_pred, mg_id).set_index('end').rename(columns={\"demand\": \"knn_demand\"}) \n",
    "svr_results = SVRModelPredictions(svr_model, svr_X_pred_scaled, mg_id, tail['end'].iloc[-1]).set_index('end').rename(columns={\"demand\": \"svr_demand\"}).rename(columns={\"demand\": \"svr_demand\"}) \n",
    "\n",
    "\n",
    "# # combine data sets\n",
    "frames = [lr_results.lr_demand, rf_results.rf_demand, xgb_results.xgb_demand, knn_results.knn_demand, svr_results.svr_demand]\n",
    "ensemble_X_pred = pd.concat(frames, axis=1, join=\"inner\")\n",
    "ensemble_X_pred['month_int'] = tail.iloc[-1].month_int\n",
    "ensemble_X_pred['day_of_week_int'] = tail.iloc[-1].day_of_week_int\n",
    "ensemble_X_pred['holiday_int'] = tail.iloc[-1].holiday_int\n",
    "\n",
    "ensemble_X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- knn_demand\n",
      "- lr_demand\n",
      "- rf_demand\n",
      "- svr_demand\n",
      "- xgb_demand\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- KNNR_Prediction\n",
      "- Linear_Prediction\n",
      "- RandomForest_Prediction\n",
      "- SVR_Prediction\n",
      "- XGBoost_Prediction\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# ensemble pred result\n",
    "ensemble_X_pred\n",
    "ensemble_X_pred.reset_index(inplace=True)\n",
    "ensemble_results = ModelPredictions(ensemble_model, ensemble_X_pred, mg_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end</th>\n",
       "      <th>id</th>\n",
       "      <th>demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>mg_01</td>\n",
       "      <td>113323.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         end     id    demand\n",
       "0 2021-04-01  mg_01  113323.4"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- day_of_week_int\n",
      "- holiday_int\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 28 features, but LinearRegression is expecting 30 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6ac655266177>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmg_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-6ac655266177>\u001b[0m in \u001b[0;36minference\u001b[0;34m(mg_id, number_of_predictions, params)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# prediction results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m#.rename(columns={\"demand\": \"lr_demand\"})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mlr_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelPredictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_X_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmg_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'end'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"demand\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"lr_demand\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mrf_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelPredictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf_X_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmg_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'end'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"demand\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"rf_demand\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mxgb_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelPredictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_X_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmg_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'end'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"demand\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"xgb_demand\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-6ac655266177>\u001b[0m in \u001b[0;36mModelPredictions\u001b[0;34m(model, X_pred, mg_id)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mModelPredictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmg_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'end'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     results = pd.DataFrame({'end':X_pred.end,\n\u001b[1;32m     14\u001b[0m                         \u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmg_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \"\"\"\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             raise ValueError(\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 28 features, but LinearRegression is expecting 30 features as input."
     ]
    }
   ],
   "source": [
    "def lagged_data_pred(df, lags):\n",
    "    df = df#[['end','id', 'demand', 'temp', 'humidity']]\n",
    "    for i in range(1, lags):\n",
    "        df[\"demand_lag_{}\".format(i)] = df['demand'].shift(i)\n",
    "        df[\"temp_lag_{}\".format(i)] = df['temp'].shift(i)\n",
    "        df[\"humidity_lag_{}\".format(i)] = df['humidity'].shift(i)\n",
    "\n",
    "    df = pd.DataFrame(df.iloc[-1]).T\n",
    "    return df\n",
    "\n",
    "def ModelPredictions(model, X_pred, mg_id):\n",
    "    prediction = model.predict(X_pred.drop(['end'], axis=1))\n",
    "    results = pd.DataFrame({'end':X_pred.end,\n",
    "                        'id':mg_id,\n",
    "                        'demand':prediction.round(1)  \n",
    "                       })    \n",
    "    return results\n",
    "\n",
    "\n",
    "# connect to sql database\n",
    "credentials = 'mysql://capstone_user:Capstone22!@capstone-database.czwmid1hzf1x.us-west-2.rds.amazonaws.com/mysqldb'\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"capstone-database.czwmid1hzf1x.us-west-2.rds.amazonaws.com\",\n",
    "  user=\"capstone_user\",\n",
    "  password=\"Capstone22!\",\n",
    "  database=\"mysqldb\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "# set params\n",
    "####################################\n",
    "mg_id = 'mg_01'\n",
    "\n",
    "params = {\n",
    "    'mg_id':mg_id\n",
    "}\n",
    "####################################\n",
    "\n",
    "\n",
    "def inference(mg_id, number_of_predictions=1, params=params):\n",
    "    for i in range(number_of_predictions):\n",
    "        tail = pd.read_sql('''SELECT * FROM microgrid_actuals_hr_24 WHERE id = %(mg_id)s ORDER BY end DESC LIMIT 10''', \n",
    "                                      con=credentials, params=params)\n",
    "        # invert the data frame\n",
    "        tail = tail.iloc[::-1]\n",
    "        # select the lastest date in the actuals table\n",
    "        date = tail.iloc[-1]['end']\n",
    "        # return a fixed frequency DatetimeIndex; grab the lastest date \n",
    "        time_index = pd.date_range(date, periods=25, freq='h')[-1]\n",
    "        # fill in empty record with latest date\n",
    "        tail.loc[tail.shape[0]] = [time_index, mg_id, np.nan, np.nan, np.nan, np.nan]\n",
    "        # set prediction month\n",
    "        tail['month'] = tail['end'].dt.strftime('%b')\n",
    "        lower_ma = [m.lower() for m in month_abbr]\n",
    "        tail['month_int'] = tail['month'].str.lower().map(lambda m: lower_ma.index(m)).astype('Int8')\n",
    "        tail['day_of_week'] = tail['end'].dt.day_name()\n",
    "        tail['day_of_week_int'] = tail['end'].dt.day_of_week\n",
    "        date_range = pd.date_range(start='2019-01-01', end='2022-01-27')\n",
    "        cal = calendar()\n",
    "        holidays = cal.holidays(start=date_range.min(), end=date_range.max())\n",
    "        tail['holiday'] = tail['end'].dt.date.astype('datetime64').isin(holidays)\n",
    "        tail[\"holiday_int\"] = tail[\"holiday\"].astype(int)\n",
    "        tail = tail[['end', 'id','demand', 'temp', 'humidity', 'month_int', 'day_of_week_int', 'holiday_int']].copy()\n",
    "\n",
    "        # lag data\n",
    "        lr_pred = lagged_data_pred(tail, 10)\n",
    "        rf_pred = lagged_data_pred(tail, 10)\n",
    "        xgb_pred = lagged_data_pred(tail, 10)\n",
    "        knn_pred = lagged_data_pred(tail, 10)\n",
    "\n",
    "        # prepare model X pred\n",
    "        lr_X_pred = lr_pred.drop(['id','demand', 'temp', 'humidity'], axis=1)\n",
    "        rf_X_pred = rf_pred.drop(['id','demand', 'temp', 'humidity'], axis=1)\n",
    "        xgb_X_pred = xgb_pred.drop(['id','demand', 'temp', 'humidity'], axis=1)\n",
    "        knn_X_pred = knn_pred.drop(['id','demand', 'temp', 'humidity'], axis=1)\n",
    "\n",
    "        # prediction results\n",
    "        #.rename(columns={\"demand\": \"lr_demand\"})\n",
    "        lr_results = ModelPredictions(lr_model, lr_X_pred, mg_id).set_index('end').rename(columns={\"demand\": \"lr_demand\"}) \n",
    "        rf_results = ModelPredictions(rf_model, rf_X_pred, mg_id).set_index('end').rename(columns={\"demand\": \"rf_demand\"}) \n",
    "        xgb_results = ModelPredictions(rf_model, xgb_X_pred, mg_id).set_index('end').rename(columns={\"demand\": \"xgb_demand\"}) \n",
    "        knn_results = ModelPredictions(knn_model, knn_X_pred, mg_id).set_index('end').rename(columns={\"demand\": \"knn_demand\"}) \n",
    "\n",
    "        # combine data sets\n",
    "        frames = [lr_results.lr_demand, rf_results.rf_demand, xgb_results.xgb_demand, knn_results.knn_demand]\n",
    "        ensemble_X_pred = pd.concat(frames, axis=1, join=\"inner\")\n",
    "        ensemble_X_pred['month_int'] = tail.iloc[-1].month_int\n",
    "\n",
    "        # ensemble pred result\n",
    "        ensemble_X_pred\n",
    "        ensemble_X_pred.reset_index(inplace=True)\n",
    "        ensemble_results = ModelPredictions(ensemble_model, ensemble_X_pred, mg_id)\n",
    "\n",
    "        ensemble_results.to_sql('microgrid_predictions_hr_24', con=credentials, if_exists='append', index=False)\n",
    "\n",
    "        time.sleep(5)\n",
    "        # select the next time step to predict\n",
    "        actual  = pd.read_sql('''SELECT * FROM microgrid_test_hr_24 WHERE id = %(mg_id)s ORDER BY end LIMIT 1''', \n",
    "                              con=credentials, params=params)\n",
    "        # write next actual from the test table to the actual table\n",
    "        actual.to_sql('microgrid_actuals_hr_24', con=credentials, if_exists='append', index=False)\n",
    "        # delete updated record from test table\n",
    "        sql = \"DELETE FROM microgrid_test_hr_24 WHERE id = '%s' AND end = '%s'\" % (mg_id, str(actual.iloc[0][0]))\n",
    "        mycursor.execute(sql)\n",
    "        mydb.commit()\n",
    "        \n",
    "i = 0\n",
    "while i < 1:\n",
    "    inference(mg_id, 1)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2021-04-01 00:00:00', freq='H')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
