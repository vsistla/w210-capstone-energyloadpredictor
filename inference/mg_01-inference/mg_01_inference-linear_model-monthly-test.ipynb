{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # MG_01 Inference - Ensemble Model - Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import mysql.connector\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "from calendar import month_abbr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error, mean_squared_error, mean_squared_log_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "import tempfile\n",
    "import boto3\n",
    "import joblib\n",
    "import time\n",
    "import pymysql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_access_key_id = 'AKIATAVK2UELBEVSLANM'\n",
    "aws_secret_access_key = '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'\n",
    "\n",
    "s3_client = boto3.client('s3', \n",
    "                         aws_access_key_id=aws_access_key_id, \n",
    "                         aws_secret_access_key=aws_secret_access_key)\n",
    "\n",
    "bucket_name = 'ipowermigrid.monthly.models'\n",
    "# key = 'linear_monthly.joblib'\n",
    "# # read model from S3 bucket\n",
    "# with tempfile.TemporaryFile() as fp:\n",
    "#     s3_client.download_fileobj(Fileobj=fp, Bucket=bucket_name, Key=key)\n",
    "#     fp.seek(0)\n",
    "#     lr_model = joblib.load(fp)\n",
    "\n",
    "# key = 'random_forest_monthly.joblib'\n",
    "# with tempfile.TemporaryFile() as fp:\n",
    "#     s3_client.download_fileobj(Fileobj=fp, Bucket=bucket_name, Key=key)\n",
    "#     fp.seek(0)\n",
    "#     rf_model = joblib.load(fp)\n",
    "    \n",
    "key = 'xgboost_model_monthly.joblib'\n",
    "with tempfile.TemporaryFile() as fp:\n",
    "    s3_client.download_fileobj(Fileobj=fp, Bucket=bucket_name, Key=key)\n",
    "    fp.seek(0)\n",
    "    xgb_model = joblib.load(fp)\n",
    "\n",
    "# key = 'knnr_model_monthly.joblib'\n",
    "# with tempfile.TemporaryFile() as fp:\n",
    "#     s3_client.download_fileobj(Fileobj=fp, Bucket=bucket_name, Key=key)\n",
    "#     fp.seek(0)\n",
    "#     knn_model = joblib.load(fp)\n",
    "    \n",
    "# key = 'ensemble_model_monthly.joblib'\n",
    "# with tempfile.TemporaryFile() as fp:\n",
    "#     s3_client.download_fileobj(Fileobj=fp, Bucket=bucket_name, Key=key)\n",
    "#     fp.seek(0)\n",
    "#     ensemble_model = joblib.load(fp)\n",
    "    \n",
    "key = 'xgb_label_encoder.pkl'\n",
    "# read model from S3 bucket\n",
    "with tempfile.TemporaryFile() as fp:\n",
    "    s3_client.download_fileobj(Fileobj=fp, Bucket=bucket_name, Key=key)\n",
    "    fp.seek(0)\n",
    "    lbl = joblib.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float, bool or category.  When\ncategorical type is supplied, DMatrix parameter `enable_categorical` must\nbe set to `True`. Invalid columns:month_int, demand_lag_1, temp_lag_1, humidity_lag_1, demand_lag_2, temp_lag_2, humidity_lag_2, demand_lag_3, temp_lag_3, humidity_lag_3, demand_lag_4, temp_lag_4, humidity_lag_4, demand_lag_5, temp_lag_5, humidity_lag_5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 102>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 103\u001b[0m     \u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmg_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36minference\u001b[0;34m(mg_id, params)\u001b[0m\n\u001b[1;32m     74\u001b[0m lr_results \u001b[38;5;241m=\u001b[39m ModelPredictions(lr_model, lr_X_pred, mg_id)\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdemand\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr_demand\u001b[39m\u001b[38;5;124m\"\u001b[39m}) \n\u001b[1;32m     75\u001b[0m rf_results \u001b[38;5;241m=\u001b[39m ModelPredictions(rf_model, rf_X_pred, mg_id)\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdemand\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrf_demand\u001b[39m\u001b[38;5;124m\"\u001b[39m}) \n\u001b[0;32m---> 76\u001b[0m xgb_results \u001b[38;5;241m=\u001b[39m \u001b[43mModelPredictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxgb_X_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmg_id\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdemand\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxgb_demand\u001b[39m\u001b[38;5;124m\"\u001b[39m}) \n\u001b[1;32m     77\u001b[0m knn_results \u001b[38;5;241m=\u001b[39m ModelPredictions(knn_model, knn_X_pred, mg_id)\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdemand\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mknn_demand\u001b[39m\u001b[38;5;124m\"\u001b[39m}) \n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# combine data sets\u001b[39;00m\n",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36mModelPredictions\u001b[0;34m(model, X_pred, mg_id)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mModelPredictions\u001b[39m(model, X_pred, mg_id):\n\u001b[0;32m---> 12\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_pred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:X_pred\u001b[38;5;241m.\u001b[39mend,\n\u001b[1;32m     14\u001b[0m                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m:mg_id,\n\u001b[1;32m     15\u001b[0m                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdemand\u001b[39m\u001b[38;5;124m'\u001b[39m:prediction\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m1\u001b[39m)  \n\u001b[1;32m     16\u001b[0m                            })    \n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:881\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 881\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmargin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    889\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[1;32m    890\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m     \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/core.py:2035\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[0;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[1;32m   2033\u001b[0m         enable_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(f \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m ft)\n\u001b[1;32m   2034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_pandas_df(data):\n\u001b[0;32m-> 2035\u001b[0m     data, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_transform_pandas_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m   2038\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _ensure_np_dtype\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/data.py:256\u001b[0m, in \u001b[0;36m_transform_pandas_df\u001b[0;34m(data, enable_categorical, feature_names, feature_types, meta, meta_type)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_sparse, is_categorical_dtype\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    251\u001b[0m     dtype\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m _pandas_dtype_mapper\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m is_sparse(dtype)\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (is_categorical_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m enable_categorical)\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dtype \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtypes\n\u001b[1;32m    255\u001b[0m ):\n\u001b[0;32m--> 256\u001b[0m     \u001b[43m_invalid_dataframe_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# handle feature names\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m meta \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/data.py:236\u001b[0m, in \u001b[0;36m_invalid_dataframe_dtype\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    231\u001b[0m         err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mDataFrame.dtypes for data must be int, float, bool or category.  When\u001b[39m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;124mcategorical type is supplied, DMatrix parameter `enable_categorical` must\u001b[39m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;124mbe set to `True`.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m \u001b[38;5;241m+\u001b[39m err\n\u001b[0;32m--> 236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float, bool or category.  When\ncategorical type is supplied, DMatrix parameter `enable_categorical` must\nbe set to `True`. Invalid columns:month_int, demand_lag_1, temp_lag_1, humidity_lag_1, demand_lag_2, temp_lag_2, humidity_lag_2, demand_lag_3, temp_lag_3, humidity_lag_3, demand_lag_4, temp_lag_4, humidity_lag_4, demand_lag_5, temp_lag_5, humidity_lag_5"
     ]
    }
   ],
   "source": [
    "def lagged_data_pred(df, lags):\n",
    "    df = df#[['end','id', 'demand', 'temp', 'humidity']]\n",
    "    for i in range(1, lags):\n",
    "        df[\"demand_lag_{}\".format(i)] = df['demand'].shift(i)\n",
    "        df[\"temp_lag_{}\".format(i)] = df['temp'].shift(i)\n",
    "        df[\"humidity_lag_{}\".format(i)] = df['humidity'].shift(i)\n",
    "\n",
    "    df = pd.DataFrame(df.iloc[-1]).T\n",
    "    return df\n",
    "\n",
    "def ModelPredictions(model, X_pred, mg_id):\n",
    "    prediction = model.predict(X_pred.drop(['end'], axis=1))\n",
    "    results = pd.DataFrame({'end':X_pred.end,\n",
    "                            'id':mg_id,\n",
    "                            'demand':prediction.round(1)  \n",
    "                           })    \n",
    "    return results\n",
    "\n",
    "# connect to sql database\n",
    "credentials = 'mysql://capstone_user:Capstone22!@capstone-database.czwmid1hzf1x.us-west-2.rds.amazonaws.com/mysqldb'\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"capstone-database.czwmid1hzf1x.us-west-2.rds.amazonaws.com\",\n",
    "  user=\"capstone_user\",\n",
    "  password=\"Capstone22!\",\n",
    "  database=\"mysqldb\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "# set params\n",
    "####################################\n",
    "mg_id = 'mg_01'\n",
    "\n",
    "params = {\n",
    "    'mg_id':mg_id\n",
    "}\n",
    "####################################\n",
    "\n",
    "\n",
    "def inference(mg_id, params=params):\n",
    "    tail = pd.read_sql('''SELECT * FROM microgrid_actuals_monthly WHERE id = %(mg_id)s ORDER BY end DESC LIMIT 10''', \n",
    "                                  con=credentials, params=params)\n",
    "    # invert the data frame\n",
    "    tail = tail.iloc[::-1]\n",
    "    # select the lastest date in the actuals table\n",
    "    date = tail.iloc[-1]['end']\n",
    "    # return a fixed frequency DatetimeIndex; grab the lastest date \n",
    "    time_index = pd.date_range(date, periods=2, freq='M')[-1]\n",
    "    # fill in empty record with latest date\n",
    "    tail.loc[tail.shape[0]] = [time_index, mg_id, np.nan, np.nan, np.nan, np.nan]\n",
    "    # set prediction month\n",
    "    tail['month'] = tail['end'].dt.strftime('%b')\n",
    "    lower_ma = [m.lower() for m in month_abbr]\n",
    "    tail['month_int'] = tail['month'].str.lower().map(lambda m: lower_ma.index(m)).astype('Int8')\n",
    "\n",
    "    tail = tail[['end', 'id','demand', 'temp', 'humidity', 'month_int']].copy()\n",
    "\n",
    "    # lag data\n",
    "    lr_pred = lagged_data_pred(tail, 3)\n",
    "    rf_pred = lagged_data_pred(tail, 4)\n",
    "    xgb_pred = lagged_data_pred(tail, 6)\n",
    "    knn_pred = lagged_data_pred(tail, 6)\n",
    "\n",
    "    # prepare model X pred\n",
    "    lr_X_pred = lr_pred.drop(['id','demand', 'temp', 'humidity'], axis=1)\n",
    "    rf_X_pred = rf_pred.drop(['id','demand', 'temp', 'humidity'], axis=1)\n",
    "    xgb_X_pred = xgb_pred.drop(['id','demand', 'temp', 'humidity'], axis=1)\n",
    "    xgb_pred['month_int'] = lbl.transform(xgb_pred['month_int'].astype(str))\n",
    "    knn_X_pred = knn_pred.drop(['id','demand', 'temp', 'humidity'], axis=1)\n",
    "\n",
    "    # prediction results\n",
    "    lr_results = ModelPredictions(lr_model, lr_X_pred, mg_id).set_index('end').rename(columns={\"demand\": \"lr_demand\"}) \n",
    "    rf_results = ModelPredictions(rf_model, rf_X_pred, mg_id).set_index('end').rename(columns={\"demand\": \"rf_demand\"}) \n",
    "    xgb_results = ModelPredictions(xgb_model, xgb_X_pred, mg_id).set_index('end').rename(columns={\"demand\": \"xgb_demand\"}) \n",
    "    knn_results = ModelPredictions(knn_model, knn_X_pred, mg_id).set_index('end').rename(columns={\"demand\": \"knn_demand\"}) \n",
    "\n",
    "    # combine data sets\n",
    "    frames = [lr_results.lr_demand, rf_results.rf_demand, xgb_results.xgb_demand, knn_results.knn_demand]\n",
    "    ensemble_X_pred = pd.concat(frames, axis=1, join=\"inner\")\n",
    "    ensemble_X_pred['month_int'] = tail.iloc[-1].month_int\n",
    "\n",
    "    # ensemble pred result\n",
    "    ensemble_X_pred.reset_index(inplace=True)\n",
    "    ensemble_results = ModelPredictions(ensemble_model, ensemble_X_pred, mg_id)\n",
    "\n",
    "    ensemble_results.to_sql('microgrid_predictions_monthly', con=credentials, if_exists='append', index=False)\n",
    "\n",
    "    time.sleep(5)\n",
    "    # select the next time step to predict\n",
    "    actual  = pd.read_sql('''SELECT * FROM microgrid_test_monthly WHERE id = %(mg_id)s ORDER BY end LIMIT 1''', \n",
    "                          con=credentials, params=params)\n",
    "    # write next actual from the test table to the actual table\n",
    "    actual.to_sql('microgrid_actuals_monthly', con=credentials, if_exists='append', index=False)\n",
    "    # delete updated record from test table\n",
    "    sql = \"DELETE FROM microgrid_test_monthly WHERE id = '%s' AND end = '%s'\" % (mg_id, str(actual.iloc[0][0]))\n",
    "    mycursor.execute(sql)\n",
    "    mydb.commit()\n",
    "        \n",
    "i = 0\n",
    "while i < 1:\n",
    "    inference(mg_id)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>xgb_demand</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-07-31</th>\n",
       "      <td>mg_01</td>\n",
       "      <td>4365047.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  xgb_demand\n",
       "end                          \n",
       "2021-07-31  mg_01   4365047.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lagged_data_pred(df, lags):\n",
    "    df = df#[['end','id', 'demand', 'temp', 'humidity']]\n",
    "    for i in range(1, lags):\n",
    "        df[\"demand_lag_{}\".format(i)] = df['demand'].shift(i)\n",
    "        df[\"temp_lag_{}\".format(i)] = df['temp'].shift(i)\n",
    "        df[\"humidity_lag_{}\".format(i)] = df['humidity'].shift(i)\n",
    "\n",
    "    df = pd.DataFrame(df.iloc[-1]).T\n",
    "    return df\n",
    "\n",
    "def ModelPredictions(model, X_pred, mg_id):\n",
    "    prediction = model.predict(X_pred.drop(['end'], axis=1))\n",
    "    results = pd.DataFrame({'end':X_pred.end,\n",
    "                            'id':mg_id,\n",
    "                            'demand':prediction.round(1)  \n",
    "                           })    \n",
    "    return results\n",
    "\n",
    "def XGBModelPredictions(model, X_pred, mg_id, time_index):\n",
    "    prediction = model.predict(X_pred)\n",
    "    results = pd.DataFrame({'end':time_index,\n",
    "                            'id':mg_id,\n",
    "                            'demand':prediction\n",
    "                           })    \n",
    "    return results\n",
    "\n",
    "\n",
    "# connect to sql database\n",
    "credentials = 'mysql://capstone_user:Capstone22!@capstone-database.czwmid1hzf1x.us-west-2.rds.amazonaws.com/mysqldb'\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "    host=\"capstone-database.czwmid1hzf1x.us-west-2.rds.amazonaws.com\",\n",
    "    user=\"capstone_user\",\n",
    "    password=\"Capstone22!\",\n",
    "    database=\"mysqldb\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "# set params\n",
    "####################################\n",
    "mg_id = 'mg_01'\n",
    "\n",
    "params = {\n",
    "    'mg_id':mg_id\n",
    "}\n",
    "####################################\n",
    "\n",
    "tail = pd.read_sql('''SELECT * FROM microgrid_actuals_monthly WHERE id = %(mg_id)s ORDER BY end DESC LIMIT 10''', \n",
    "                                  con=credentials, params=params)\n",
    "# invert the data frame\n",
    "tail = tail.iloc[::-1]\n",
    "# select the lastest date in the actuals table\n",
    "date = tail.iloc[-1]['end']\n",
    "# return a fixed frequency DatetimeIndex; grab the lastest date \n",
    "time_index = pd.date_range(date, periods=2, freq='M')[-1]\n",
    "# fill in empty record with latest date\n",
    "tail.loc[tail.shape[0]] = [time_index, mg_id, np.nan, np.nan, np.nan, np.nan]\n",
    "# set prediction month\n",
    "tail['month'] = tail['end'].dt.strftime('%b')\n",
    "lower_ma = [m.lower() for m in month_abbr]\n",
    "tail['month_int'] = tail['month'].str.lower().map(lambda m: lower_ma.index(m)).astype('Int8')\n",
    "\n",
    "tail = tail[['end', 'id','demand', 'temp', 'humidity', 'month_int']].copy()\n",
    "\n",
    "\n",
    "# lag data\n",
    "# lr_pred = lagged_data_pred(tail, 3)\n",
    "# rf_pred = lagged_data_pred(tail, 4)\n",
    "xgb_pred = lagged_data_pred(tail, 6)\n",
    "#.astype(float, errors = 'raise')\n",
    "# xgb_pred\n",
    "\n",
    "# knn_pred = lagged_data_pred(tail, 6)\n",
    "\n",
    "# prepare model X pred\n",
    "# lr_X_pred = lr_pred.drop(['id','demand', 'temp', 'humidity'], axis=1)\n",
    "# rf_X_pred = rf_pred.drop(['id','demand', 'temp', 'humidity'], axis=1)\n",
    "xgb_X_pred = xgb_pred.drop(['id','demand', 'temp', 'humidity'], axis=1)\n",
    "xgb_X_pred = xgb_X_pred.loc[:, xgb_X_pred.columns != 'end'].astype(float, errors = 'raise')\n",
    "xgb_X_pred['month_int'] = lbl.transform(xgb_pred['month_int'].astype(str))\n",
    "xgb_X_pred.dtypes\n",
    "# knn_X_pred = knn_pred.drop(['id','demand', 'temp', 'humidity'], axis=1)\n",
    "\n",
    "# prediction results\n",
    "# lr_results = ModelPredictions(lr_model, lr_X_pred, mg_id).set_index('end').rename(columns={\"demand\": \"lr_demand\"}) \n",
    "# rf_results = ModelPredictions(rf_model, rf_X_pred, mg_id).set_index('end').rename(columns={\"demand\": \"rf_demand\"}) \n",
    "xgb_results = XGBModelPredictions(xgb_model, xgb_X_pred, mg_id, tail['end'].iloc[-1]).set_index('end').rename(columns={\"demand\": \"xgb_demand\"}) \n",
    "xgb_results\n",
    "#.set_index('end').rename(columns={\"demand\": \"xgb_demand\"}) \n",
    "# knn_results = ModelPredictions(knn_model, knn_X_pred, mg_id).set_index('end').rename(columns={\"demand\": \"knn_demand\"}) \n",
    "\n",
    "\n",
    "# combine data sets\n",
    "# frames = [lr_results.lr_demand, rf_results.rf_demand, xgb_results.xgb_demand, knn_results.knn_demand]\n",
    "# ensemble_X_pred = pd.concat(frames, axis=1, join=\"inner\")\n",
    "# ensemble_X_pred['month_int'] = tail.iloc[-1].month_int\n",
    "\n",
    "# # ensemble pred result\n",
    "# ensemble_X_pred.reset_index(inplace=True)\n",
    "# ensemble_results = ModelPredictions(ensemble_model, ensemble_X_pred, mg_id)\n",
    "\n",
    "# ensemble_results.to_sql('microgrid_predictions_monthly', con=credentials, if_exists='append', index=False)\n",
    "\n",
    "# time.sleep(5)\n",
    "# # select the next time step to predict\n",
    "# actual  = pd.read_sql('''SELECT * FROM microgrid_test_monthly WHERE id = %(mg_id)s ORDER BY end LIMIT 1''', \n",
    "#                       con=credentials, params=params)\n",
    "# # write next actual from the test table to the actual table\n",
    "# actual.to_sql('microgrid_actuals_monthly', con=credentials, if_exists='append', index=False)\n",
    "# # delete updated record from test table\n",
    "# sql = \"DELETE FROM microgrid_test_monthly WHERE id = '%s' AND end = '%s'\" % (mg_id, str(actual.iloc[0][0]))\n",
    "# mycursor.execute(sql)\n",
    "# mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
