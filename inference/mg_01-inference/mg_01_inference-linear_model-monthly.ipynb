{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # MG_01 Inference - Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import mysql.connector\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "from calendar import month_abbr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error, mean_squared_error, mean_squared_log_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import datetime\n",
    "import tempfile\n",
    "import boto3\n",
    "import joblib\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_monthly.joblib\n",
      "random_forest_monthly.joblib\n",
      "knnr_model_monthly.joblib\n"
     ]
    }
   ],
   "source": [
    "aws_access_key_id = 'AKIATAVK2UELBEVSLANM'\n",
    "aws_secret_access_key = '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'\n",
    "\n",
    "s3_client = boto3.client('s3', \n",
    "                         aws_access_key_id=aws_access_key_id, \n",
    "                         aws_secret_access_key=aws_secret_access_key)\n",
    "\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "rf_model = RandomForestRegressor()\n",
    "# xbg_model = XGBRegressor()\n",
    "knn_model = KNeighborsRegressor()\n",
    "\n",
    "bucket_name = 'ipowermigrid.monthly.models'\n",
    "# key = ['linear_monthly.joblib', 'random_forest_monthly.joblib', 'xgboost_model_monthly.joblib', 'knnr_model_monthly.joblib']\n",
    "# model = [lr_model, rf_model, xbg_model, knn_model]\n",
    "\n",
    "key = ['linear_monthly.joblib', 'random_forest_monthly.joblib', 'knnr_model_monthly.joblib']\n",
    "model = [lr_model, rf_model, knn_model]\n",
    "\n",
    "\n",
    "# read models from S3 bucket\n",
    "for k, m in zip(key, model):\n",
    "    with tempfile.TemporaryFile() as fp:\n",
    "        s3_client.download_fileobj(Fileobj=fp, Bucket=bucket_name, Key=k)\n",
    "        fp.seek(0)\n",
    "        m = joblib.load(fp)\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagged_data_pred(df):\n",
    "    df = df#[['end','id', 'demand', 'temp', 'humidity']]\n",
    "    for i in range(1, 10):\n",
    "        df[\"demand_lag_{}\".format(i)] = df['demand'].shift(i)\n",
    "        df[\"temp_lag_{}\".format(i)] = df['temp'].shift(i)\n",
    "        df[\"humidity_lag_{}\".format(i)] = df['humidity'].shift(i)\n",
    "\n",
    "    df = pd.DataFrame(df.iloc[-1]).T\n",
    "    return df\n",
    "\n",
    "def ModelPredictions(model, X_pred, mg_id):\n",
    "    prediction = model.predict(X_pred.drop(['end'], axis=1))\n",
    "    results = pd.DataFrame({'end':X_pred.end,\n",
    "                        'id':mg_id,\n",
    "                        'demand':prediction.round(1)  \n",
    "                       })    \n",
    "    return results\n",
    "\n",
    "\n",
    "# connect to sql database\n",
    "credentials = 'mysql://capstone_user:Capstone22!@capstone-database.czwmid1hzf1x.us-west-2.rds.amazonaws.com/mysqldb'\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"capstone-database.czwmid1hzf1x.us-west-2.rds.amazonaws.com\",\n",
    "  user=\"capstone_user\",\n",
    "  password=\"Capstone22!\",\n",
    "  database=\"mysqldb\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "# set params\n",
    "####################################\n",
    "mg_id = 'mg_01'\n",
    "\n",
    "params = {\n",
    "    'mg_id':mg_id\n",
    "}\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tail = pd.read_sql('''SELECT * FROM microgrid_actuals_monthly WHERE id = %(mg_id)s ORDER BY end DESC LIMIT 10''', \n",
    "                                      con=credentials, params=params)\n",
    "# invert the data frame\n",
    "tail = tail.iloc[::-1]\n",
    "# select the lastest date in the actuals table\n",
    "date = tail.iloc[-1]['end']\n",
    "# return a fixed frequency DatetimeIndex; grab the lastest date \n",
    "time_index = pd.date_range(date, periods=16, freq='min')[-1]\n",
    "# fill in empty record with latest date\n",
    "tail.loc[tail.shape[0]] = [time_index, mg_id, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end</th>\n",
       "      <th>id</th>\n",
       "      <th>demand</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>month_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>mg_01</td>\n",
       "      <td>3699497.59</td>\n",
       "      <td>86.0</td>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-28</td>\n",
       "      <td>mg_01</td>\n",
       "      <td>3039411.20</td>\n",
       "      <td>74.0</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>mg_01</td>\n",
       "      <td>3484392.00</td>\n",
       "      <td>76.0</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>mg_01</td>\n",
       "      <td>3459385.60</td>\n",
       "      <td>79.0</td>\n",
       "      <td>98</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>mg_01</td>\n",
       "      <td>3399993.60</td>\n",
       "      <td>90.0</td>\n",
       "      <td>96</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         end     id      demand  temp  humidity  month_int\n",
       "0 2021-03-31  mg_01  3699497.59  86.0        98          3\n",
       "1 2021-02-28  mg_01  3039411.20  74.0        99          2\n",
       "2 2021-01-31  mg_01  3484392.00  76.0        98          1\n",
       "3 2020-12-31  mg_01  3459385.60  79.0        98         12\n",
       "4 2020-11-30  mg_01  3399993.60  90.0        96         11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tail.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"\"\"\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"\"\"\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"\"\"\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"\"\"\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/samueljohngomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "def lagged_data_pred(df):\n",
    "    df = df#[['end','id', 'demand', 'temp', 'humidity']]\n",
    "    for i in range(1, 10):\n",
    "        df[\"demand_lag_{}\".format(i)] = df['demand'].shift(i)\n",
    "        df[\"temp_lag_{}\".format(i)] = df['temp'].shift(i)\n",
    "        df[\"humidity_lag_{}\".format(i)] = df['humidity'].shift(i)\n",
    "\n",
    "    df = pd.DataFrame(df.iloc[-1]).T\n",
    "    return df\n",
    "\n",
    "def ModelPredictions(model, X_pred, mg_id):\n",
    "    prediction = model.predict(X_pred.drop(['end'], axis=1))\n",
    "    results = pd.DataFrame({'end':X_pred.end,\n",
    "                        'id':mg_id,\n",
    "                        'demand':prediction.round(1)  \n",
    "                       })    \n",
    "    return results\n",
    "\n",
    "\n",
    "# connect to sql database\n",
    "credentials = 'mysql://capstone_user:Capstone22!@capstone-database.czwmid1hzf1x.us-west-2.rds.amazonaws.com/mysqldb'\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"capstone-database.czwmid1hzf1x.us-west-2.rds.amazonaws.com\",\n",
    "  user=\"capstone_user\",\n",
    "  password=\"Capstone22!\",\n",
    "  database=\"mysqldb\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "# set params\n",
    "####################################\n",
    "mg_id = 'mg_01'\n",
    "\n",
    "params = {\n",
    "    'mg_id':mg_id\n",
    "}\n",
    "####################################\n",
    "\n",
    "\n",
    "def inference(mg_id, number_of_predictions=1, params=params):\n",
    "    for i in range(number_of_predictions):\n",
    "        tail = pd.read_sql('''SELECT * FROM microgrid_actuals_15m WHERE id = %(mg_id)s ORDER BY end DESC LIMIT 672''', \n",
    "                                      con=credentials, params=params)\n",
    "        # invert the data frame\n",
    "        tail = tail.iloc[::-1]\n",
    "        # select the lastest date in the actuals table\n",
    "        date = tail.iloc[-1]['end']\n",
    "        # return a fixed frequency DatetimeIndex; grab the lastest date \n",
    "        time_index = pd.date_range(date, periods=16, freq='min')[-1]\n",
    "        # fill in empty record with latest date\n",
    "        tail.loc[tail.shape[0]] = [time_index, mg_id, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "\n",
    "        tail['month'] = tail['end'].dt.strftime('%b')\n",
    "\n",
    "        lower_ma = [m.lower() for m in month_abbr]\n",
    "\n",
    "        # one-liner with Pandas\n",
    "        tail['month_int'] = tail['month'].str.lower().map(lambda m: lower_ma.index(m)).astype('Int8')\n",
    "\n",
    "        tail['day_of_week'] = tail['end'].dt.day_name()\n",
    "\n",
    "        tail['day_of_week_int'] = tail['end'].dt.day_of_week\n",
    "\n",
    "        date_range = pd.date_range(start='2019-01-01', end='2022-01-27')\n",
    "\n",
    "        cal = calendar()\n",
    "        holidays = cal.holidays(start=date_range.min(), end=date_range.max())\n",
    "\n",
    "        tail['holiday'] = tail['end'].dt.date.astype('datetime64').isin(holidays)\n",
    "\n",
    "        tail[\"holiday_int\"] = tail[\"holiday\"].astype(int)\n",
    "\n",
    "        tail = tail[['end', 'id','demand', 'temp', 'humidity', 'month_int', 'day_of_week_int', 'holiday_int']].copy() \n",
    "\n",
    "        # transform records to lagged data format\n",
    "        pred = lagged_data_pred(tail)\n",
    "\n",
    "        X_pred = pred.drop(['id','demand', 'temp', 'humidity'], axis=1)\n",
    "\n",
    "        # set predict value\n",
    "        results = ModelPredictions(lr_from_s3, X_pred, mg_id)\n",
    "        # write results to sql table\n",
    "        results.to_sql('microgrid_predictions_15m', con=credentials, if_exists='append', index=False)\n",
    "        \n",
    "        time.sleep(2)\n",
    "        # select the next time step to predict\n",
    "        actual  = pd.read_sql('''SELECT * FROM microgrid_test_15m WHERE id = %(mg_id)s ORDER BY end LIMIT 1''', \n",
    "                              con=credentials, params=params)\n",
    "        # write next actual from the test table to the actual table\n",
    "        actual.to_sql('microgrid_actuals_15m', con=credentials, if_exists='append', index=False)\n",
    "        # delete updated record from test table\n",
    "        sql = \"DELETE FROM microgrid_test_15m WHERE id = '%s' AND end = '%s'\" % (mg_id, str(actual.iloc[0][0]))\n",
    "        mycursor.execute(sql)\n",
    "        mydb.commit()\n",
    "i = 0\n",
    "while i < 5:\n",
    "    inference(mg_id, 1)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
