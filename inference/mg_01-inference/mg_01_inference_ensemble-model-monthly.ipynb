{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # MG_01 Inference - Ensemble Model - Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import mysql.connector\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "from calendar import month_abbr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error, mean_squared_error, mean_squared_log_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "import tempfile\n",
    "import boto3\n",
    "import joblib\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_model loaded\n",
      "rf_model loaded\n",
      "xgb_model loaded\n",
      "xgb_label_encoder loaded\n",
      "knn_model loaded\n",
      "ensemble_model loaded\n"
     ]
    }
   ],
   "source": [
    "# read model from S3 bucket\n",
    "aws_access_key_id = 'AKIATAVK2UELBEVSLANM'\n",
    "aws_secret_access_key = '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'\n",
    "\n",
    "s3_client = boto3.client('s3', \n",
    "                         aws_access_key_id=aws_access_key_id, \n",
    "                         aws_secret_access_key=aws_secret_access_key)\n",
    "bucket_name = 'ipowermigrid.monthly.models'\n",
    "\n",
    "# lr_model load\n",
    "key = 'linear_monthly.joblib'\n",
    "with tempfile.TemporaryFile() as fp:\n",
    "    s3_client.download_fileobj(Fileobj=fp, Bucket=bucket_name, Key=key)\n",
    "    fp.seek(0)\n",
    "    lr_model = joblib.load(fp)\n",
    "    print('lr_model loaded')\n",
    "    \n",
    "# rf_model load\n",
    "key = 'random_forest_monthly.joblib'\n",
    "with tempfile.TemporaryFile() as fp:\n",
    "    s3_client.download_fileobj(Fileobj=fp, Bucket=bucket_name, Key=key)\n",
    "    fp.seek(0)\n",
    "    rf_model = joblib.load(fp)\n",
    "    print('rf_model loaded')\n",
    "    \n",
    "# xgb_model load   \n",
    "key = 'xgboost_model_monthly.joblib'\n",
    "with tempfile.TemporaryFile() as fp:\n",
    "    s3_client.download_fileobj(Fileobj=fp, Bucket=bucket_name, Key=key)\n",
    "    fp.seek(0)\n",
    "    xgb_model = joblib.load(fp)\n",
    "    print('xgb_model loaded')\n",
    "\n",
    "# xgb_label_encoder load \n",
    "key = 'xgb_label_encoder.pkl'\n",
    "# read model from S3 bucket\n",
    "with tempfile.TemporaryFile() as fp:\n",
    "    s3_client.download_fileobj(Fileobj=fp, Bucket=bucket_name, Key=key)\n",
    "    fp.seek(0)\n",
    "    lbl = joblib.load(fp)\n",
    "    print('xgb_label_encoder loaded')\n",
    "\n",
    "# knn_model load\n",
    "key = 'knnr_model_monthly.joblib'\n",
    "with tempfile.TemporaryFile() as fp:\n",
    "    s3_client.download_fileobj(Fileobj=fp, Bucket=bucket_name, Key=key)\n",
    "    fp.seek(0)\n",
    "    knn_model = joblib.load(fp)\n",
    "    print('knn_model loaded')\n",
    "    \n",
    "# ensemble_model load    \n",
    "key = 'ensemble_model_monthly.joblib'\n",
    "with tempfile.TemporaryFile() as fp:\n",
    "    s3_client.download_fileobj(Fileobj=fp, Bucket=bucket_name, Key=key)\n",
    "    fp.seek(0)\n",
    "    ensemble_model = joblib.load(fp)\n",
    "    print('ensemble_model loaded')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- knn_demand\n",
      "- lr_demand\n",
      "- rf_demand\n",
      "- xgb_demand\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- Prediction_KNNR\n",
      "- Prediction_linear\n",
      "- Prediction_randomforest\n",
      "- Prediction_xgboost\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# load functions\n",
    "def lagged_data_pred(df, lags):\n",
    "    df = df#[['end','id', 'demand', 'temp', 'humidity']]\n",
    "    for i in range(1, lags):\n",
    "        df[\"demand_lag_{}\".format(i)] = df['demand'].shift(i)\n",
    "        df[\"temp_lag_{}\".format(i)] = df['temp'].shift(i)\n",
    "        df[\"humidity_lag_{}\".format(i)] = df['humidity'].shift(i)\n",
    "\n",
    "    df = pd.DataFrame(df.iloc[-1]).T\n",
    "    return df\n",
    "\n",
    "def ModelPredictions(model, X_pred, mg_id):\n",
    "    prediction = model.predict(X_pred.drop(['end'], axis=1))\n",
    "    results = pd.DataFrame({'end':X_pred.end,\n",
    "                            'id':mg_id,\n",
    "                            'demand':prediction.round(1)  \n",
    "                           })    \n",
    "    return results\n",
    "\n",
    "def XGBModelPredictions(model, X_pred, mg_id, time_index):\n",
    "    prediction = model.predict(X_pred)\n",
    "    results = pd.DataFrame({'end':time_index,\n",
    "                            'id':mg_id,\n",
    "                            'demand':prediction\n",
    "                           })    \n",
    "    return results\n",
    "\n",
    "# connect to sql database\n",
    "credentials = 'mysql://capstone_user:Capstone22!@capstone-database.czwmid1hzf1x.us-west-2.rds.amazonaws.com/mysqldb'\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"capstone-database.czwmid1hzf1x.us-west-2.rds.amazonaws.com\",\n",
    "  user=\"capstone_user\",\n",
    "  password=\"Capstone22!\",\n",
    "  database=\"mysqldb\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "# set params\n",
    "####################################\n",
    "mg_id = 'mg_01'\n",
    "\n",
    "params = {\n",
    "    'mg_id':mg_id\n",
    "}\n",
    "####################################\n",
    "\n",
    "\n",
    "def inference_monthly(mg_id, params=params):\n",
    "    tail = pd.read_sql('''SELECT * FROM microgrid_actuals_monthly WHERE id = %(mg_id)s ORDER BY end DESC LIMIT 10''', \n",
    "                                  con=credentials, params=params)\n",
    "    # invert the data frame\n",
    "    tail = tail.iloc[::-1]\n",
    "    # select the lastest date in the actuals table\n",
    "    date = tail.iloc[-1]['end']\n",
    "    # return a fixed frequency DatetimeIndex; grab the lastest date \n",
    "    time_index = pd.date_range(date, periods=2, freq='M')[-1]\n",
    "    # fill in empty record with latest date\n",
    "    tail.loc[tail.shape[0]] = [time_index, mg_id, np.nan, np.nan, np.nan, np.nan]\n",
    "    # set prediction month\n",
    "    tail['month'] = tail['end'].dt.strftime('%b')\n",
    "    lower_ma = [m.lower() for m in month_abbr]\n",
    "    tail['month_int'] = tail['month'].str.lower().map(lambda m: lower_ma.index(m)).astype('Int8')\n",
    "\n",
    "    tail = tail[['end', 'id','demand', 'temp', 'humidity', 'month_int']].copy()\n",
    "\n",
    "    # lag data\n",
    "    lr_pred = lagged_data_pred(tail, 3)\n",
    "    rf_pred = lagged_data_pred(tail, 4)\n",
    "    xgb_pred = lagged_data_pred(tail, 6)\n",
    "    knn_pred = lagged_data_pred(tail, 6)\n",
    "\n",
    "    # prepare model X pred\n",
    "    lr_X_pred = lr_pred.drop(['id','demand', 'temp', 'humidity'], axis=1)\n",
    "    rf_X_pred = rf_pred.drop(['id','demand', 'temp', 'humidity'], axis=1)\n",
    "    xgb_X_pred = xgb_pred.drop(['id','demand', 'temp', 'humidity'], axis=1)\n",
    "    xgb_X_pred = xgb_X_pred.loc[:, xgb_X_pred.columns != 'end'].astype(float, errors = 'raise')\n",
    "    xgb_X_pred['month_int'] = lbl.transform(xgb_pred['month_int'].astype(str))\n",
    "    knn_X_pred = knn_pred.drop(['id','demand', 'temp', 'humidity'], axis=1)\n",
    "\n",
    "    # prediction results\n",
    "    lr_results = ModelPredictions(lr_model, lr_X_pred, mg_id).set_index('end').rename(columns={\"demand\": \"lr_demand\"}) \n",
    "    rf_results = ModelPredictions(rf_model, rf_X_pred, mg_id).set_index('end').rename(columns={\"demand\": \"rf_demand\"}) \n",
    "    xgb_results = XGBModelPredictions(xgb_model, xgb_X_pred, mg_id, tail['end'].iloc[-1]).set_index('end').rename(columns={\"demand\": \"xgb_demand\"}) \n",
    "    knn_results = ModelPredictions(knn_model, knn_X_pred, mg_id).set_index('end').rename(columns={\"demand\": \"knn_demand\"}) \n",
    "\n",
    "    # combine data sets\n",
    "    frames = [lr_results.lr_demand, rf_results.rf_demand, xgb_results.xgb_demand, knn_results.knn_demand]\n",
    "    ensemble_X_pred = pd.concat(frames, axis=1, join=\"inner\")\n",
    "    ensemble_X_pred['month_int'] = tail.iloc[-1].month_int\n",
    "\n",
    "    # ensemble pred result\n",
    "    ensemble_X_pred.reset_index(inplace=True)\n",
    "    ensemble_results = ModelPredictions(ensemble_model, ensemble_X_pred, mg_id)\n",
    "    ensemble_results.to_sql('microgrid_predictions_monthly', con=credentials, if_exists='append', index=False)\n",
    "\n",
    "    #time.sleep(5)\n",
    "    # select the next time step to predict\n",
    "    actual  = pd.read_sql('''SELECT * FROM microgrid_test_monthly WHERE id = %(mg_id)s ORDER BY end LIMIT 1''', \n",
    "                          con=credentials, params=params)\n",
    "    # write next actual from the test table to the actual table\n",
    "    actual.to_sql('microgrid_actuals_monthly', con=credentials, if_exists='append', index=False)\n",
    "    \n",
    "    # delete updated record from test table\n",
    "    sql = \"DELETE FROM microgrid_test_monthly WHERE id = '%s' AND end = '%s'\" % (mg_id, str(actual.iloc[0][0]))\n",
    "    mycursor.execute(sql)\n",
    "    mydb.commit()\n",
    "        \n",
    "i = 0\n",
    "while i < 1:\n",
    "    inference_monthly(mg_id)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
